program: train.py
method: bayes
name: Sweep_PPO_Recurrent
metric:
  name: mean_reward_test
  goal: maximize
parameters:
  objetivo:
    value: 0
  atraso:
    value: -1
  batch_size:
    values: [8, 16, 32, 64, 128, 256]
  n_steps:
    values: [8, 16, 32, 64, 128, 256, 512, 1024, 2048]
  gamma:
    values: [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999]
  learning_rate:
    distribution: uniform
    min: 1e-05
    max: 1.0
  ent_coef:
    distribution: uniform
    min: 0.00000001
    max: 0.1
  clip_range:
    values: [0.1, 0.2, 0.3, 0.4]
  n_epochs:
    values: [1, 5, 10, 20]
  gae_lambda:
    values: [0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0]
  max_grad_norm:
    values: [0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 5]
  vf_coef:
    min: 0.0
    max: 1.0
  # net_arch:
  #   values: ["tiny", "small", "medium"]
  
