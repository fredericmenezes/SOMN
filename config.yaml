program: train.py
method: bayes
name: Hiperparametrizacao PPO (novas formulações)
metric:
  name: mean_reward_test
  goal: maximize
parameters:
  objetivo:
    value: 0
  atraso:
    value: -1
  batch_size:
    values: [16, 32, 64, 128, 256]
  ent_coef:
    distribution: uniform
    min: 0.0
    max: 0.01
  gae_lambda:
    distribution: uniform
    min: 0.9
    max: 1.0
  gamma:
    distribution: uniform
    min: 0.8
    max: 1.0
  learning_rate:
    distribution: uniform
    min: 0.00001
    max: 0.1
  n_epochs:
    distribution: int_uniform
    min: 5
    max: 30
  n_steps:
    values: [1024, 1536, 2048, 2304, 2560, 2816, 3072, 3328, 3584, 3840, 4096]
  target_kl:
    distribution: uniform
    min: 0.003
    max: 0.03
