Solution:
Optimal Schedule Length: 17.0
Machine 0: job_1_task_0
           [0,2]
Machine 1: job_1_task_1
           [2,4]
Machine 2:
Machine 3: job_1_task_2
           [4,6]
Machine 4: job_1_task_3
           [6,8]
Machine 5: job_1_task_4
           [8,9]
Machine 6: job_1_task_5
           [9,12]
Machine 7: job_1_task_6
           [12,13]
Machine 8: job_1_task_7
           [13,16]
Machine 9: job_1_task_8
           [16,17]
Traceback (most recent call last):
  File "c:\Users\alyss\OneDrive\Área de Trabalho\SOMN\Treinamento.py", line 70, in <module>
    model.learn(total_timesteps=3328*10)
  File "c:\Users\alyss\OneDrive\Área de Trabalho\SOMN\Stable_baselines3\PPO.py", line 440, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "c:\Users\alyss\OneDrive\Área de Trabalho\SOMN\Stable_baselines3\OnPolicyAlgirithm.py", line 262, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\alyss\OneDrive\Área de Trabalho\SOMN\Stable_baselines3\OnPolicyAlgirithm.py", line 179, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alyss\OneDrive\Área de Trabalho\SOMN\.venv\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 197, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\alyss\OneDrive\Área de Trabalho\SOMN\.venv\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alyss\OneDrive\Área de Trabalho\SOMN\.venv\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\alyss\OneDrive\Área de Trabalho\SOMN\Ambiente_SOMN\Somn.py", line 427, in step
    self.product_scheduling(Somn.time, action)
  File "c:\Users\alyss\OneDrive\Área de Trabalho\SOMN\Ambiente_SOMN\Somn.py", line 294, in product_scheduling
    Somn.instance.Output()  ## precisa salvar a lista de resultados
    ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\alyss\OneDrive\Área de Trabalho\SOMN\JobShop\JobShop.py", line 127, in Output
    wandb.log({'Objective Value': self.solver.ObjectiveValue(), 'steps': BaseAlgorithm.getNumTimeStep})
                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'BaseAlgorithm' has no attribute 'getNumTimeStep'