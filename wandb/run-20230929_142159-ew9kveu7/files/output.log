Solution:
Optimal Schedule Length: 23.0
Machine 0: job_1_task_0
           [0,1]
Machine 1: job_1_task_1
           [1,2]
Machine 2: job_1_task_2
           [2,6]
Machine 3:
Machine 4: job_1_task_3
           [6,9]
Machine 5: job_1_task_4
           [9,11]
Machine 6: job_1_task_5
           [11,14]
Machine 7: job_1_task_6
           [14,17]
Machine 8: job_1_task_7
           [17,19]
Machine 9: job_1_task_8
           [19,23]
Traceback (most recent call last):
  File "c:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\Treinamento.py", line 70, in <module>
    model.learn(total_timesteps=3328*10)
  File "c:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\Stable_baselines3\PPO.py", line 440, in learn
    return super().learn(
           ^^^^^^^^^^^^^^
  File "c:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\Stable_baselines3\OnPolicyAlgirithm.py", line 262, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\Stable_baselines3\OnPolicyAlgirithm.py", line 179, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\.venv\Lib\site-packages\stable_baselines3\common\vec_env\base_vec_env.py", line 197, in step
    return self.step_wait()
           ^^^^^^^^^^^^^^^^
  File "C:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\.venv\Lib\site-packages\stable_baselines3\common\vec_env\dummy_vec_env.py", line 58, in step_wait
    obs, self.buf_rews[env_idx], terminated, truncated, self.buf_infos[env_idx] = self.envs[env_idx].step(
                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\.venv\Lib\site-packages\stable_baselines3\common\monitor.py", line 94, in step
    observation, reward, terminated, truncated, info = self.env.step(action)
                                                       ^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\Ambiente_SOMN\Somn.py", line 427, in step
    self.product_scheduling(Somn.time, action)
  File "c:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\Ambiente_SOMN\Somn.py", line 294, in product_scheduling
    Somn.instance.Output()  ## precisa salvar a lista de resultados
    ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\alyss\OneDrive\Área de Trabalho\OPTSIMFLEX\JobShop\JobShop.py", line 127, in Output
    wandb.log({'Objective Value': self.solver.ObjectiveValue(), 'steps': BaseAlgorithm.num_timesteps})
                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: type object 'BaseAlgorithm' has no attribute 'num_timesteps'